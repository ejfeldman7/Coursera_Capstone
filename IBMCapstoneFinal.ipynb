{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to complete the data analysis of car accident data for the capstone project for IBM's Data Science program on Coursera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project - The Battle of the Neighborhoods (Week 2)\n",
    "### Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Exploratory Data Analysis](#eploratory)\n",
    "* [Modeling](#modeling)\n",
    "* [Conclusions](#conclusions)\n",
    "* [Future Work](#future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1: Background\n",
    "As we have increased the number of drivers on the road over the course of the last century we have also seen an unfortunate increase in the number of accidents. As car manufacturers and city planners have worked diligently to not only decrease the likelihood of accidents but also the resultant severity of accidents when they do unforunately occur, there is still work to be done to better predict the occurence and level of severity. \n",
    "\n",
    "## 1.2 Business Use Case\n",
    "In this project we seek to answer a question on the behalf of the Seattle Department of Transportation and the drivers of the city of Seattle regarding car accident severity. Namely, we want to be able to predict if accident severity, in particular if an accident results in soley damage to property or personal injury, based on the conditions of the road and the lighting at the time of the accident. If we can answer this question well enough, can we use it to change our education of drivers or send alerts during particularly treacherous conditions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Sources\n",
    "For the purposes of this project we are [using a dataset](https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Metadata.pdf \"Dataset\") of all accidents recorded in Seattle by the Seattle Police Department from 2004 to present. We have isolated only the data pertaining to road conditions based on factors such as rain, standing water, mud, oil, or other factors and those for lighting conditions based on time of day and street lights. We have coded our severity scores as either accidents that result in damage to property or those that also include injury to those in any vehicle involved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\ejfel\\Google Drive\\Work\\IBM DS\\Capstone\\ExampleData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's take a closer look at our dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Cleaning\n",
    "   Data was read from a CSV file and into a Pandas dataframe for cleaning, structuring, and analysis. There were a number of pieces of data that were included that were deemed not pertinent to our analysis. Included in this were items such as descriptions of the accident, categories of locations, counts of pedestrians and passengers, and the data, among others. These items were not related to the analysis of the impact light and road conditions on accident severity. This will make up our feature set. We also take this opportunity to retitle our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['SEVERITYCODE','ROADCOND','LIGHTCOND','X','Y']]\n",
    "features.rename(columns={'SEVERITYCODE':'Severity', 'ROADCOND':'Precipitation','LIGHTCOND':'Lighting','X':'Longitude','Y':'Latitutde'}, inplace=True)\n",
    "all(isinstance(column, str) for column in features.columns)\n",
    "features.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Once the data had been reduced to pertinent items, we identified and dropped any accidents which were missing data from any column, as it would be impossible to know accident severity or conditions without them being given. Furthermore, many accidents listed lighting or road conditions as \"Other\" or \"Unknown.\" For the same reasons as missing data, these items were removed from our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.dropna()\n",
    "features=features[~features.ROADCOND.str.contains('Other') == True]\n",
    "features=features[~features.ROADCOND.str.contains(\"Unknown\") == True]\n",
    "features=features[~features.LIGHTCOND.str.contains(\"Unknown\") == True]\n",
    "features=features[~features.LIGHTCOND.str.contains(\"Other\") == True]\n",
    "features.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Then, we replaced all our categorical variables with integer values to be able to apply our models and metrics more cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_precip = preprocessing.LabelEncoder()\n",
    "le_precip.fit(['Dry','Wet','Ice','Oil','Sand/Mud/Dirt','Snow/Slush','Standing Water'])\n",
    "X[:,0] = le_precip.transform(X[:,0]) \n",
    "\n",
    "\n",
    "le_light = preprocessing.LabelEncoder()\n",
    "le_light.fit([ 'Dark - No Street Lights', 'Dark - Street Lights Off', 'Dark - Street Lights On','Dawn','Daylight','Dusk'])\n",
    "X[:,1] = le_light.transform(X[:,1])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define our target set, severity, for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features[\"Severity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Finally, we moved on to dealing with the imbalance in our target of severity, with many more accidents being damage to property but not injuries to passengers. If left unchecked, we would expect our model to run with relatively high accuracy by always predicting solely property damage, but not actually providing any kind of prediction based on lighting and road condtions. This imbalance is not the result of improper sampling and should not be ignored, as it points to the truth that most accidents do not result in injuries to passengers, but still may result in costly damage for drivers. We have chosen to downsample the accidents with property damage to represent a set of the same size as the accidents with personal injury. In this way, our models can analyze for structure between the target and the feature set, and not get tricked by the imbalance of real outcomes in our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = features[features.Severity==0]\n",
    "df_minority = features[features.Severity==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=55000,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "features_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "features_downsampled.Severity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We then repeated the exercise previously done on our data set to replace our categorical variables with integer values for our modeling work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_down = features_downsampled[[ 'Precipitation','Lighting']].values\n",
    "\n",
    "le_precip = preprocessing.LabelEncoder()\n",
    "le_precip.fit(['Dry','Wet','Ice','Oil','Sand/Mud/Dirt','Snow/Slush','Standing Water'])\n",
    "X_down[:,0] = le_precip.transform(X_down[:,0]) \n",
    "\n",
    "\n",
    "le_light = preprocessing.LabelEncoder()\n",
    "le_light.fit([ 'Dark - No Street Lights', 'Dark - Street Lights Off', 'Dark - Street Lights On','Dawn','Daylight','Dusk'])\n",
    "X_down[:,1] = le_light.transform(X_down[:,1])\n",
    "X_down\n",
    "\n",
    "y_down = features_downsampled['Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis<a name=\"exploratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how severity appears to be impacted by our different features. This data is the original data and NOT the down sampled amounts that we will use for training our models later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lighting = features.groupby('Lighting').Severity.value_counts()\n",
    "Lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precipitation = features.groupby('Precipitation').Severity.value_counts()\n",
    "Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = features.groupby(['Lighting']).Severity.value_counts().rename(\"count\")\n",
    "frequencyL = k / k.groupby(level=0).sum()\n",
    "frequencyL\n",
    "\n",
    "c = features.groupby(['Precipitation']).Severity.value_counts().rename(\"count\")\n",
    "frequencyP = c / c.groupby(level=0).sum()\n",
    "frequencyP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better visual, here is that same information in a bar chart for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencyP.plot(kind='bar',figsize=(9,9),\n",
    "              color=['coral','coral','darkslateblue','darkslateblue'])\n",
    "plt.title('Severity of Accident by Precipitation')\n",
    "\n",
    "plt.ylabel('Proportion in Condition')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencyL.plot(kind='bar',figsize=(9,9),\n",
    "              color=['coral','coral','darkslateblue','darkslateblue'])\n",
    "plt.title('Severity of Accident by Lighting')\n",
    "\n",
    "plt.ylabel('Proportion in Condition')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predictive Modeling <a name=\"modeling\"></a>\n",
    "There were three types of models that we used to predict accident severity: logistic regression, decision trees, and k-Nearest Neighbor classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( Xnorm, y, test_size=0.2, random_state=4)\n",
    "Xnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "yhat = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see here that this model may have a decent accuracy score overall, it never makes a prediction for the higher severity level. This is a result of the bias in our target data set that was used for training and what our downsampling method should seek to account for. Let's see how that downsampling helps us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split( X_down, y_down, test_size=0.2, random_state=4)\n",
    "LR2 = LogisticRegression(C=0.01, solver='liblinear').fit(X_train1,y_train1.values.ravel())\n",
    "yhat_down = LR2.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test1, yhat_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see while our overall accuracy has dropped considerably, our model is now making true predicitons between the higher and lower severity level. Considering these two outcomes, it seems that this may not be our best choice for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Decision Tree and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrashTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "CrashTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTree = CrashTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, predTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(X_train, y_train)\n",
    " \n",
    "pred_y_4 = clf_4.predict(X_test)\n",
    " \n",
    "print( np.unique( pred_y_4 ) )\n",
    "print( accuracy_score(y_test, pred_y_4) )\n",
    "\n",
    "prob_y_4 = clf_4.predict_proba(X_test)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y_test, prob_y_4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also verify that downsampling will not play a positive role for our tree classifiers in this case, which we can see here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrashTree2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "CrashTree2.fit(X_train1,y_train1)\n",
    "predTree2 = CrashTree2.predict(X_test1)\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test1, predTree1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_down = RandomForestClassifier()\n",
    "clf_down.fit(X_train1, y_train1)\n",
    " \n",
    "pred_down = clf_4.predict(X_test1)\n",
    " \n",
    "print( np.unique( pred_down ) )\n",
    "print( accuracy_score(y_test1, pred_down) )\n",
    "\n",
    "prob_down = clf_down.predict_proba(X_test1)\n",
    "prob_down = [p[1] for p in prob_down]\n",
    "print( roc_auc_score(y_test1, prob_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 4\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "yhat = neigh.predict(X_test)\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = 10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Nabors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusions <a name=\"conclusions\"></a>\n",
    "In this project, we have created and evaluated a number of models for predicting accident severity based on lighting and road conditions. These can be of great use to first responders in allocating resources, cities in planning for increased lighting or advisories for upcoming weather, or for driver's education about potentially dangerous driving situations to avoid if possible. We can see from our metrics that the two models that will provide our most accurate predictions going forward would be the 2-Nearest Neighbors and the Decision Tree Classifier created from the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Future Directions<a name=\"future\"></a>\n",
    "This data set provided a wealth of information, but missed a elements that we know exist as well. For example, no data points were for accidents with highest levels of severity in accidents (accidents no just with injury to passengers but more severe cases involving fatalities).\n",
    "    Models in this study do not explain how or why these accidents occur, simply predicting correlation to particular weather and lighting conditions. They have not included detail into how the lighting conditions might impact a driver different based on time of year, if the drivers are local or not, or how drivers might have been impacted by choices of signage, speed limits, or past experiences. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
